---
title: "p8105_hw3_xw2676.Rmd"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
  warning = FALSE,
  fig.width = 8,
  fig.height = 6,
  out.width = "90%")
library(tidyverse)
library(ggridges)
library(patchwork)
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem1
```{r}
library(p8105.datasets)
data("instacart") 
instacart %>% 
  head(8) %>% 
  knitr::kable(format = "html", caption = "Table 1 An example from the dataset")
```

There are `r nrow(instacart)` observations and `r ncol(instacart)` variables in instacart dataset. The key variables are `r colnames(instacart[1])`，`r colnames(instacart[2])`, `r colnames(instacart[8])`, `r colnames(instacart[9])`, `r colnames(instacart[11])`, `r colnames(instacart[12])`,`r colnames(instacart[13])`,`r colnames(instacart[14])`,`r colnames(instacart[15])`. For example, there is a customer whose id is 112108 bought an order whose id is 1 in 10:00 am Thursday. Among these products, such as yogurt or cheese, there are 4 products that he have bought before. And this order is his fourth order. It has been 9 days ever since his prior order. 

#### 1）
```{r}
aisle_data_ordered = group_by(instacart,aisle,aisle_id) %>% ## split data into datasets of different aisles
  summarise(n = n()) %>% ## generate a dataset which comprises of every aisle and number of items ordered from it.
  arrange(-n) 
max_aisle = head(aisle_data_ordered,1)
knitr::kable(aisle_data_ordered, format = "html",caption = "Table 2 Numbers of items bought from each aisle")
```

So there are `r nrow(aisle_data_ordered)` aisles, and items are ordered mostly from "`r aisle_data_ordered[1,1]`" aisle. The reason for this may be that fresh vegetables are must for every person, and people must buy much of them every day. 

#### 2)

```{r}
filter(aisle_data_ordered, n > 10000) %>%  ## filter the aisles from which the number of items ordered is larger than 10000.
ggplot(aes(x = reorder(aisle, n), y = n)) +     ## make a geom_point plot.
  geom_col(fill = "blue") +
  labs(
    title = "Plot 1 Items ordered from each aisle",
    x = "Aisle",
    y = "Number of items ordered from each aisle",
    caption = "Data from the instacart package"
  ) +
  coord_flip()

```

From the plot above, we can see that "fresh fruits" and "fresh vegetables" are the aisles from which most items bought. The reason is the same as the first question: fresh vegetables and fresh fruits are a must for every person, and people must buy much of them every day.

#### 3）
```{r}
## generate table of three most popular items in baking ingredients.
filter(instacart, aisle %in% c("baking ingredients", "dog food care", 
                      "packaged vegetables fruits")) %>% 
  group_by(aisle,product_name) %>% 
  summarise(selling_times = n()) %>% 
  arrange(-selling_times) %>% 
  top_n(3) %>% 
  knitr::kable(format = "html", caption = "Table 3 Most popular products",
               col.names = c("Aisle", "Product_name",
                             "Selling_Times"))
```

From the results above, we can see that the three most popular items in each of the aisles are some basic stuff for baking ingredients, dog food care and packaged vegetables fruits. And because most people eat packaged vegetables fruits, so the number of times each item is ordered from it is the most. And there are less people have pets, so the number of times each item is ordered from it is the least.

#### 4)
```{r}
filter(instacart, product_name%in% c("Pink Lady Apples", "Coffee Ice Cream")) %>%  
  group_by(order_dow, product_name) %>% 
  summarize(
    mean_order_time_of_day  = mean(order_hour_of_day)) %>% 
  pivot_wider(
    names_from = order_dow,
    values_from = mean_order_time_of_day
  )  %>% 
   knitr::kable(format = "html", caption = "Table 4 Mean Order time of two products", col.names =
                 c("Product Name", "Sunday", "Monday", "Tuesday",
                   "Wednesday", "Thursday", "Friday", "Saturday"))
```
From the results above, we can see that people bought pink lady apples mostly approximately in 12:00 and 14:00. And people bought coffee ice cream mostly approximately in 14:00 and 15:00. 

## Problem2
```{r}
library(p8105.datasets)
data("brfss_smart2010")   
Overall_Health = janitor::clean_names(brfss_smart2010) %>%  
 filter(topic == "Overall Health",            
 response %in% c("Excellent","Very good", "Good","Fair","Poor")) %>%  
  mutate(response = forcats::fct_relevel(response, 
                                        c("Poor", "Fair", "Good", 
                                          "Very good","Excellent")))
```
Format the data to use appropriate variable names, focus on the “Overall Health” topic, and  include only responses from “Excellent” to “Poor”, organize responses as a factor taking levels ordered from “Poor” to “Excellent”.

#### 1)
```{r}
Overall_Health_2002 = filter(Overall_Health,year == 2002) %>% 
  group_by(locationabbr,locationdesc) %>% 
  summarise(n = n()) %>% 
  group_by(locationabbr) %>% 
  summarise(observed_locations_2002 = n()) %>% 
  filter(observed_locations_2002 >= 7)
  knitr::kable(format = "html", Overall_Health_2002, caption = "Table 5 Overall Health of 2002")
Overall_Health_2010 = filter(Overall_Health,year == 2010) %>% 
  group_by(locationabbr,locationdesc) %>% 
  summarise(n = n()) %>% 
  group_by(locationabbr) %>% 
  summarise(observed_locations_2010 = n()) %>% 
  filter(observed_locations_2010 >= 7) 
  knitr::kable(format = "html", Overall_Health_2010, caption = "Table 6 Overall Health of 2010")
```

In 2002, `r Overall_Health_2002$locationabbr` were observed at 7 or more locations.
In 2010, `r Overall_Health_2010$locationabbr` were observed at 7 or more locations. I found that there are more locations observed in 2010.

#### 2)
```{r}
filter(Overall_Health, response == "Excellent") %>% 
  select(year,locationabbr,locationdesc,data_value) %>% 
  group_by(year,locationabbr) %>% 
  summarize(mean_data_value = mean(data_value,na.rm=TRUE)) %>% 
  ggplot(aes(x = year, y = mean_data_value, color = locationabbr)) + 
    geom_point() + geom_line() +
  labs(
       x    = "year",
       y    = "average data value",
       title = "Plot 2  Average data value over time within a state "
       )
```

We can see from the plot that in year 2005, the average value of excellent response in most states are the least.

#### 3)
```{r}
filter(Overall_Health, (year == "2006"| year =="2010") & locationabbr == "NY") %>%           group_by(year,locationdesc,response) %>% 
  summarise(
    mean_data_value_of_response = mean(data_value)
  ) %>% 
  ggplot(aes(x = response, y = mean_data_value_of_response, fill = locationdesc)) +
  geom_bar(stat = "identity", position = "dodge", width = 0.5) + 
  facet_grid(~year) + 
  viridis::scale_fill_viridis(discrete = TRUE)+
labs(
       x    = "mean data value",
       title = "Plot 3  Mean data value of responses in 2006 and 2010 in NY state "
       )+
theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

This plot shows the mean data value of responses among locations in NY State in 2006 and 2010. Bronx and Erie were included in 2010. The value of “very good” also had a significant increase in year 2010.

## Problem 3
#### 1)
```{r}
accel_data = read_csv("./accel_data.csv") %>% 
  janitor::clean_names() %>% 
  pivot_longer(
    activity_1:activity_1440,
    names_to = "activity",
    names_prefix = "activity_",
    values_to = "activity_counts"
  ) %>% 
  mutate(
    day = as.factor(day),
    day = forcats::fct_relevel(day, c("Sunday","Monday", "Tuesday",
                          "Wednesday", 
                          "Thursday", "Friday", 
                          "Saturday")),
    activity = as.numeric(activity),
    weekday_weekend = ifelse(day %in% c("Saturday","Sunday"),"weekend","weekday"),
    weekday_weekend = as.factor(weekday_weekend),
    day_num = factor(day,levels = c("Sunday","Monday", "Tuesday",
                          "Wednesday", 
                          "Thursday", "Friday", 
                          "Saturday"),labels = c(1:7)) )%>% 
    mutate(
      day_order = week-1,
      day_order = day_order * 7,
      day_order = day_order + as.numeric(day_num),
      day_order = as.numeric(day_order)
    ) %>% 
  mutate(
    time = activity/60
  ) %>% 
  select(-day_num) %>% 
  arrange(day_order) 
```

There are `r nrow(accel_data)` observations and `r ncol(accel_data)` variables in accel_data dataset. The key variables are `r colnames(accel_data[5])`.

#### 2)
```{r}
total_activity = group_by(accel_data, day_order, day,week) %>% 
  summarise(
    total_activity = sum(activity_counts)
  ) 
knitr::kable(total_activity, format = "html", caption = "Table7 Total acitvity of each day")

## generate a plot about the total activity of every day in every week to see the trend.
ggplot(total_activity, aes(x = day_order, y = total_activity, color = day)) +
  geom_line(alpha = .5) +
labs(
       x    = "day order",
       title = "Plot 3  Total activity of each day "
       )  + 
scale_x_continuous(
    breaks = c(1, 8, 15, 22,29), 
    labels = c("1", "8", "15", "22", "29"),
    limits = c(1, 35))
```

From the plot above, we can see that the total activity fluctuate more strongly in Saturday and Sunday, and more gently in weekdays. 

#### 3)
```{r}
accel_data %>% 
  group_by(day_order) %>% 
  ggplot(aes(x = time, y = activity_counts, color = day)) +
  geom_line() + viridis::scale_color_viridis(discrete = TRUE)+
labs(
       x = "time",
       y = "activity counts",
       title = "Plot 3 Every day activity counts"
       )

```

From the plot above, we can see that the activity counts is large during 6:00am to 22:00pm, especially large at around 10:00 am and 21:00 pm in all days of the week, which indicates that he had more activities at these times. What is more, we can see that Monday, Tuesday are more flatter, and Sunday, Saturday and Sunday are more fluctuate. 


















